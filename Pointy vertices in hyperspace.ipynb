{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Pointy Vertices in Hyperspace and Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####From Wikipedia  \n",
    "  \n",
    "The volume of a sphere of $n$ dimensions is  \n",
    "  \n",
    "$V_n(R) = \\pi^{n/2} R^n\\ \\ /\\ \\ \\Gamma(\\frac{n}{2} + 1)$.  \n",
    "  \n",
    "The volume of a hypercube with edge length $2 R$ is simply  \n",
    "\n",
    "$(2R)^n$.  \n",
    "  \n",
    "For the same $R$ and center, a hypersphere will be inscribed within the hypercube.  \n",
    "\n",
    "![Embedded sphere](embedded_sphere-.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By taking the ratio of the hypercube's volume to that of the hypersphere, we can infer the fraction of the vertices' volumes that are on the exterior of the inscribed hyperspheres:\n",
    "  \n",
    "$2^n \\Gamma(\\frac{n}{2} + 1) / \\pi^{n/2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Ratio of volumes hypercubes / hyperspheres as a function of dimension *n*:  \n",
    "|n|${2^n \\Gamma(\\frac{n}{2} + 1)\\ /\\ \\pi^{n/2}}$|  \n",
    "|-|-------------------------------------------|\n",
    "|2|$\\ \\ \\ $1.273$\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ $|\n",
    "|3|$\\ \\ \\ $1.910                                   |\n",
    "|4|$\\ \\ \\ $3.242                                   |\n",
    "|10|401.543                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a square, the exterior corners contain 27% of the volume of an inscribed circle, and for a sphere, the vertices contain 90% of the volume of the inscribed sphere.  \n",
    "\n",
    "It's clear that this ``fractional extra volume'' increases dramatically with dimension.  \n",
    "\n",
    "###And about Lasso regression *vs.* Ridge regression:  \n",
    "  \n",
    "  \n",
    "When looking at the image above, we learn something important from recognizing that the formulation of Ridge regression tends to solve for coefficient values on the surface of a hypersphere, while Lasso regression favors coefficient values that follow edges of a hypercube.  \n",
    "  \n",
    "In high dimensions, the volumes of the exterior vertices are very large, so it is very likely that coefficients constrained by Lasso will take on values near vertices. In Ridge regression, in contrast, the coefficients follow trajectories along the surface of a hypersphere, so a mix of values of all coefficients is likely.  \n",
    "  \n",
    "If your goal is to drive down the number of coefficients surviving an initial formulation of a problem (dimensionality reduction), Lasso regression is a good idea."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
